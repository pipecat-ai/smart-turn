import torch
from torch import nn
import torch.nn.functional as F
from transformers import Wav2Vec2PreTrainedModel, Wav2Vec2Model, AutoConfig, AutoFeatureExtractor
from optimum.exporters.onnx import export
from optimum.exporters.onnx.config import OnnxConfig
from optimum.utils.input_generators import DummyInputGenerator, DummyAudioInputGenerator
from optimum.utils.normalized_config import NormalizedConfig
from collections import OrderedDict
import os
import numpy as np
from pathlib import Path
import argparse
import sys

ROOT = Path(__file__).resolve().parents[1]
sys.path.append(str(ROOT))

from model import Wav2Vec2ForEndpointing 

DEFAULT_MODEL_DIR = ROOT / "v2-model"
DEFAULT_ONNX_DIR = ROOT / "smart-turn-v2-onnx"

class DummyAttentionMaskGenerator(DummyInputGenerator):
    """
    A dummy input generator that creates an attention mask for audio models.
    """
    SUPPORTED_INPUT_NAMES = ("attention_mask",)

    def __init__(self, task: str, normalized_config: NormalizedConfig, **kwargs):
        """
        This __init__ method accepts the arguments passed by the exporter.
        They are not used in this class but are required by the API.
        """
        self.sequence_length = int(
            normalized_config.sampling_rate * normalized_config.dummy_audio_duration
        )

    def generate(self, batch_size: int, framework: str = "pt", **kwargs):
        """
        Generates a dummy attention_mask. It calculates the sequence_length internally
        to match the length generated by the DummyAudioInputGenerator.
        """
        if isinstance(batch_size, str):
            batch_size = 1
            
        shape = (batch_size, self.sequence_length)
        return torch.ones(*shape, dtype=torch.int64)

class Wav2Vec2ForEndpointingOnnxConfig(OnnxConfig):
    NORMALIZED_CONFIG_CLASS = NormalizedConfig
    DUMMY_INPUT_GENERATOR_CLASSES = (DummyAudioInputGenerator, DummyAttentionMaskGenerator)


    @property
    def inputs(self) -> "OrderedDict[str, OrderedDict[int, str]]":
        """
        Defines the model's inputs for the ONNX graph.
        """
        return OrderedDict(
            [
                ("input_values", {0: "batch_size", 1: "sequence_length"}),
                ("attention_mask", {0: "batch_size", 1: "sequence_length"}),
            ]
        )

    @property
    def outputs(self) -> "OrderedDict[str, OrderedDict[int, str]]":
        """
        Defines the model's outputs for the ONNX graph.
        """
        return OrderedDict(
            [
                ("logits", {0: "batch_size"}),
            ]
        )

def verify_onnx_model(model, onnx_model_path, feature_extractor):
    """
    Verifies that the ONNX model output matches the PyTorch model output.
    """
    print("\n" + "-" * 50)
    print("üöÄ Starting model verification...")
    print("-" * 50)

    try:
        import onnxruntime as ort
    except ImportError:
        print("‚ùå Error: onnxruntime is not installed.")
        print("Please install it with: pip install onnxruntime")
        return

    sampling_rate = feature_extractor.sampling_rate
    dummy_audio = np.random.randn(1, sampling_rate * 2)
    inputs = feature_extractor(
        dummy_audio, sampling_rate=sampling_rate, return_tensors="pt", return_attention_mask=True
    )
    input_values = inputs.input_values
    attention_mask = inputs.attention_mask

    model.eval()
    with torch.no_grad():
        pytorch_outputs = model(input_values=input_values, attention_mask=attention_mask)
        pytorch_logits = pytorch_outputs["logits"].numpy()

    print(f"PyTorch model output (logits): {pytorch_logits}")

    ort_session = ort.InferenceSession(str(onnx_model_path))
    onnx_inputs = {
        "input_values": input_values.numpy(),
        "attention_mask": attention_mask.numpy().astype(np.int64)
    }
    onnx_logits = ort_session.run(None, onnx_inputs)[0]
    print(f"ONNX model output (logits):    {onnx_logits}")

    try:
        np.testing.assert_allclose(pytorch_logits, onnx_logits, rtol=1e-3, atol=1e-4)
        print("\n‚úÖ SUCCESS: The ONNX model's output matches the PyTorch model's output.")
        print("The conversion was successful and the model is ready to use.")
    except AssertionError as e:
        print("\n‚ùå FAILURE: The ONNX model's output does NOT match the PyTorch model's output.")
        print("There might be an issue with the conversion process.")
        print(f"Assertion Error: {e}")
    
    print("-" * 50)


def main(model_path: Path, output_path: Path):
    onnx_model_file = output_path / "model.onnx"
    
    if not model_path.exists():
        print(f"Error: Model directory not found at '{model_path}'")
        return

    print(f"Loading custom model from: {model_path}")

    config = AutoConfig.from_pretrained(str(model_path))
    model = Wav2Vec2ForEndpointing.from_pretrained(str(model_path), config=config)
    feature_extractor = AutoFeatureExtractor.from_pretrained(str(model_path))
    
    model.config.sampling_rate = feature_extractor.sampling_rate
    model.config.dummy_audio_duration = 2.0


    custom_onnx_config = Wav2Vec2ForEndpointingOnnxConfig(model.config, task="audio-classification")

    print("\nStarting ONNX export...")

    export(
        model=model,
        config=custom_onnx_config,
        output=onnx_model_file,
        opset=14,
    )

    print(f"‚úÖ Export complete!")
    print(f"Your ONNX model has been saved to: {onnx_model_file.resolve()}")

    verify_onnx_model(model, onnx_model_file, feature_extractor)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Export Smart-Turn model to ONNX")
    parser.add_argument("--model", default=os.getenv("SMART_TURN_MODEL", DEFAULT_MODEL_DIR), help="Path to fine-tuned model directory")
    parser.add_argument("--out",   default=os.getenv("SMART_TURN_ONNX", DEFAULT_ONNX_DIR), help="Directory to write ONNX model")
    args = parser.parse_args()

    try:
        import onnxruntime
    except ImportError:
        print("‚ùå  onnxruntime not installed.  pip install onnxruntime")
        sys.exit(1)

    out_dir = Path(args.out)
    out_dir.mkdir(parents=True, exist_ok=True)

    main(Path(args.model), out_dir)
